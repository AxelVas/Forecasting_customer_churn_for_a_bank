# Прогнозирование уйдёт клиент из банка в ближайшее время или нет
<!--- ![image](https://user-images.githubusercontent.com/76148212/122680393-9319c900-d1f7-11eb-968e-580fc50f5fc8.png) --->

## Описание проекта
Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.

Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. В наше распоряжение предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. 

Требуется построить модель с предельно большим значением *F1*-меры(от 0.59 или выше). Дополнительно проверим *F1*-меру на тестовой выборке.

А так же будем измерять *AUC-ROC* и сравнивать её значение с *F1*-мерой.

   *© Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)* 
## Стэк:
`Pandas`
`Matplotlib`
`Seaborn`
`numpy`
`sklearn`
`math`
`машинное обучение`

## Краткое содержание проделанной работы<br>
<i>Из банка стали уходить клиенты каждый месяц. 
Спрогнозирована вероятность ухода клиента из банка в ближайшее время.
Построена модель с предельно большим значением F1-меры с последующей проверкой на тестовой выборке. Доведена метрика до 0.62. 
Дополнительно измерен AUC-ROC, соотнесен с F1-мерой.
Обучение с учителем. Работа с несбалансированными данными.</i>

## Данные и выводы
<i>В завершении выбора наилучшей модели, мы дополнительно сравнили её показатели с константной моделью DummyClassifier, у которой при значении accurcy = 1, значение меры F1 = 0.0, в отличии от нашей модели на тестовой выборке, где accurcy = 0,83 со значением меры F1 = 0.62. Таким образом мы построили модель с предельно большим значением F1-меры = 0,62 и проверили её на адекватность в сравнении с константной моделью.</i>

---

#### Если проект не открывается, его можно просмотреть по ссылке: <a href='https://nbviewer.jupyter.org/github/AxelVas/Forecasting_customer_churn_for_a_bank/blob/main/%D0%9F%D1%80%D0%BE%D0%B3%D0%BD%D0%BE%D0%B7%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D1%83%D0%B9%D0%B4%D1%91%D1%82_%D0%BA%D0%BB%D0%B8%D0%B5%D0%BD%D1%82_%D0%B8%D0%B7_%D0%B1%D0%B0%D0%BD%D0%BA%D0%B0_%D0%B2_%D0%B1%D0%BB%D0%B8%D0%B6%D0%B0%D0%B9%D1%88%D0%B5%D0%B5_%D0%B2%D1%80%D0%B5%D0%BC%D1%8F_%D0%B8%D0%BB%D0%B8_%D0%BD%D0%B5%D1%82_%D0%BF%D1%80%D0%BE%D0%B5%D0%BA%D1%82_sh.ipynb'>Forecasting_customer_churn_for_a_bank</a>

<!--- # Полное содержание проекта
<a id='start'></a>

### 1. Подготовка данных
   * <a href='#step_1'> Загружаем библиотеки </a>
   * <a href='#step_1.1'> Открокем файл по адресу (datasets/users_behavior.csv) и изучим данные</a>
   * <a href='#step_1.4'> Заполним недостающие данные </a>
   
   * <a href='#step_1.3'> Воспользуемся функцией `describe` для анализа всех данных в таблице</a>
   * <a href='#step_1.2'>Построим графики зависимостей значений в таблице для наглядного представления о распределнии данных</a>
   
### 2. Исследование задачи
   *<a href='#step_2'> Применим порядковое и прямое кодирование к данным в таблице при помощи функции `OrdinalEncoder ` и `pd.get_dummies()` </a>
   * <a href='#step_2.1.1'> Используем функцию `train_test_split` для разделения основного массива данных на `три` выборки 20% 20% 60% </a>
   * <a href='#step_2.1'> Проверим равномерность разделения данных при помощи функции `shape`</a>
   * <a href='#step_2.2'> Посмотрим на распределение классов в данных </a>

   * <a href='#step_2.3'> Приведём данные столбцоов '`CreditScore`','`Age','Balance`','`EstimatedSalary`' к одному масштабу</a>
       * <a href='#step_2.2.end'> Вывод</a>  
   * <a href='#step_2.4'> Выбор моделей без учёта дисбаланса</a>
       * <a href='#step_2.4'> Логистическая регрессия </a>
       * <a href='#step_2.5'> Деревья выбора (DecisionTree) </a>
       * <a href='#step_2.6'> Случайный лес (RandomForest) </a>              
   * <a href='#step_2.end'> Вывод </a>
   
### 3. Борьба с дисбалансом
   * <a href='#step_3'> Посмотрим на баланс распределения классов в данных</a>
   * <a href='#step_3.1'>Первый способ - `balanced`</a>
       * <a href='#step_3.1'>Логистическая регрессия balanced</a>
       * <a href='#step_3.1.1'>Деревья выбора (DecisionTree) balanced</a>
       
       * <a href='#step_3.2'> Случайный лес (RandomForest) balanced</a>
   * <a href='#step_3.3'> Второй способ борьбы с дисбалансом данных (увелиение количества примеров `upsample`)</a>
       * <a href='#step_3.3'> Создадим функцию, для увеличения выборки по первому [1] классу данных и уменьшение по нулевому [0] классу</a>
   * <a href='#step_3.4'> Проверим данные на наших моделях</a>
       * <a href='#step_3.4'> Логистическая регрессия </a>
       * <a href='#step_3.5'> Деревья выбора (DecisionTree)</a>
       * <a href='#step_3.6'> Случайный лес (RandomForest)</a>
   * <a href='#step_3.6.1'> Определим порог классификации</a>
   * <a href='#step_3.7'> Вычислим ROC-AUC для валидационной модели</a>
   * <a href='#step_3.8'> Сведём полученные данные по F1- мере в одну таблицу</a>

   * <a href='#step_3.end'> Вывод </a>
   
### 4. Тестирование модели
   * <a href='#step_4.1'> Протестируем нашу лучшую модель `Случайный лес (RandomForest)` на полных данных, включая валидационную выборку</a>
   * <a href='#step_4.2'> Обучим модель на полных данных и выведем показатели </a>
   * <a href='#step_4.3'> ROC-AUC для тестовой модели</a>
   * <a href='#step_4.end'> Вывод </a>

### 5. Вывод
   * <a href='#step_5.end'> Вывод </a>
   --- >
