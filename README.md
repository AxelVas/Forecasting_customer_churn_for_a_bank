# Прогнозирование уйдёт клиент из банка в ближайшее время или нет
![image](https://user-images.githubusercontent.com/76148212/122680393-9319c900-d1f7-11eb-968e-580fc50f5fc8.png)

## Описание проекта
Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.

Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. В наше распоряжение предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. 

Требуется построить модель с предельно большим значением *F1*-меры(от 0.59 или выше). Дополнительно проверим *F1*-меру на тестовой выборке.

А так же будем измерять *AUC-ROC* и сравнивать её значение с *F1*-мерой.

   *© Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)* 
## Стэк:
`Pandas`
`Matplotlib`
`Seaborn`
`numpy`
`sklearn`
`math`
`машинное обучение`

## Краткое содержание проделанной работы:<br>
>Из банка стали уходить клиенты каждый месяц. 
Спрогнозирована вероятность ухода клиента из банка в ближайшее время.
Построена модель с предельно большим значением F1-меры с последующей проверкой на тестовой выборке. Доведена метрика до 0.59. 
Дополнительно измерен AUC-ROC, соотнесен с F1-мерой.
Обучение с учителем. Работа с несбалансированными данными.
---
# Полное содержание проекта
<a id='start'></a>

### 1. Подготовка данных
   * <a href='#step_1'> Загружаем библиотеки </a>
   * <a href='#step_1.1'> Открокем файл по адресу (datasets/users_behavior.csv) и изучим данные</a>
   * <a href='#step_1.4'> Заполним недостающие данные </a>
   
   * <a href='#step_1.3'> Воспользуемся функцией `describe` для анализа всех данных в таблице</a>
   * <a href='#step_1.2'>Построим графики зависимостей значений в таблице для наглядного представления о распределнии данных</a>
   
### 2. Исследование задачи
   *<a href='#step_2'> Применим порядковое и прямое кодирование к данным в таблице при помощи функции `OrdinalEncoder ` и `pd.get_dummies()` </a>
   * <a href='#step_2.1.1'> Используем функцию `train_test_split` для разделения основного массива данных на `три` выборки 20% 20% 60% </a>
   * <a href='#step_2.1'> Проверим равномерность разделения данных при помощи функции `shape`</a>
   * <a href='#step_2.2'> Посмотрим на распределение классов в данных </a>

   * <a href='#step_2.3'> Приведём данные столбцоов '`CreditScore`','`Age','Balance`','`EstimatedSalary`' к одному масштабу</a>
       * <a href='#step_2.2.end'> Вывод</a>  
   * <a href='#step_2.4'> Выбор моделей без учёта дисбаланса</a>
       * <a href='#step_2.4'> Логистическая регрессия </a>
       * <a href='#step_2.5'> Деревья выбора (DecisionTree) </a>
       * <a href='#step_2.6'> Случайный лес (RandomForest) </a>              
   * <a href='#step_2.end'> Вывод </a>
   
### 3. Борьба с дисбалансом
   * <a href='#step_3'> Посмотрим на баланс распределения классов в данных</a>
   * <a href='#step_3.1'>Первый способ - `balanced`</a>
       * <a href='#step_3.1'>Логистическая регрессия balanced</a>
       * <a href='#step_3.1.1'>Деревья выбора (DecisionTree) balanced</a>
       
       * <a href='#step_3.2'> Случайный лес (RandomForest) balanced</a>
   * <a href='#step_3.3'> Второй способ борьбы с дисбалансом данных (увелиение количества примеров `upsample`)</a>
       * <a href='#step_3.3'> Создадим функцию, для увеличения выборки по первому [1] классу данных и уменьшение по нулевому [0] классу</a>
   * <a href='#step_3.4'> Проверим данные на наших моделях</a>
       * <a href='#step_3.4'> Логистическая регрессия </a>
       * <a href='#step_3.5'> Деревья выбора (DecisionTree)</a>
       * <a href='#step_3.6'> Случайный лес (RandomForest)</a>
   * <a href='#step_3.6.1'> Определим порог классификации</a>
   * <a href='#step_3.7'> Вычислим ROC-AUC для валидационной модели</a>
   * <a href='#step_3.8'> Сведём полученные данные по F1- мере в одну таблицу</a>

   * <a href='#step_3.end'> Вывод </a>
   
### 4. Тестирование модели
   * <a href='#step_4.1'> Протестируем нашу лучшую модель `Случайный лес (RandomForest)` на полных данных, включая валидационную выборку</a>
   * <a href='#step_4.2'> Обучим модель на полных данных и выведем показатели </a>
   * <a href='#step_4.3'> ROC-AUC для тестовой модели</a>
   * <a href='#step_4.end'> Вывод </a>

### 5. Вывод
   * <a href='#step_5.end'> Вывод </a>
   ---
